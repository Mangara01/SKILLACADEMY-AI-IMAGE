{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be58b994-bc68-4166-91d5-282418b78864",
      "metadata": {
        "id": "be58b994-bc68-4166-91d5-282418b78864"
      },
      "source": [
        "# Project: Image/Object Detection Portfolio (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01",
      "metadata": {
        "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01"
      },
      "source": [
        "**Instructions for Students:**\n",
        "\n",
        "Please carefully follow these steps to complete and submit your assignment:\n",
        "\n",
        "1. **Completing the Assignment**: You are required to work on and complete all tasks in the provided assignment. Be disciplined and ensure that you thoroughly engage with each task.\n",
        "   \n",
        "2. **Creating a Google Drive Folder**: If you don't previously have a folder for collecting assignments, you must create a new folder in your Google Drive. This will be a repository for all your completed assignment files, helping you keep your work organized and easy to access.\n",
        "   \n",
        "3. **Uploading Completed Assignment**: Upon completion of your assignment, make sure to upload all necessary files, involving codes, reports, and related documents into the created Google Drive folder. Save this link in the 'Student Identity' section and also provide it as the last parameter in the `submit` function that has been provided.\n",
        "   \n",
        "4. **Sharing Folder Link**: You're required to share the link to your assignment Google Drive folder. This is crucial for the submission and evaluation of your assignment.\n",
        "   \n",
        "5. **Setting Permission toPublic**: Please make sure your **Google Drive folder is set to public**. This allows your instructor to access your solutions and assess your work correctly.\n",
        "\n",
        "Adhering to these procedures will facilitate a smooth assignment process for you and the reviewers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca56111-19cb-46c0-a77b-11bd18c55673",
      "metadata": {
        "id": "eca56111-19cb-46c0-a77b-11bd18c55673"
      },
      "source": [
        "**Description:**\n",
        "\n",
        "Welcome to your image/object detection portfolio project assignment for AI Bootcamp. In this project you will apply what you've learned so far into real-world applications.\n",
        "\n",
        "You are free to create anything as long as it's within the category of image based or object detection application or model.\n",
        "\n",
        "Some ideas for your applications:\n",
        "* Image Classification application that can correctly identify local Indonesian food.\n",
        "* Object Detection application that can identify correctly animals inside the picture.\n",
        "* Object Detection application that can identify correctly animals inside a video.\n",
        "\n",
        "For submission, please upload the model and application to Huggingface or your own Github account.\n",
        "\n",
        "Your submission will be graded and scored and will add a maximum of 15 points to your final score.\n",
        "\n",
        "Remember, the key to mastering these concepts is practice. Do apply your knowledge, and don't hesitate to ask questions if you encounter any difficulties. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "213a611a-c434-4894-ba35-689963ee5274",
      "metadata": {
        "id": "213a611a-c434-4894-ba35-689963ee5274"
      },
      "outputs": [],
      "source": [
        "# @title #### Student Identity\n",
        "student_id = \"REA7YDK9\" # @param {type:\"string\"}\n",
        "name = \"Mangara Haposan Immanuel Siagian\" # @param {type:\"string\"}\n",
        "drive_link = \"https://drive.google.com/drive/folders/1oRRHNoCZQ5h7qiUKiEkQ0zGIBP27NvUI?usp=sharing\"  # @param {type:\"string\"}\n",
        "assignment_id = \"00_image_portfolio_project\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c97aef3-b747-49f7-99e0-4086c03e4200",
      "metadata": {
        "id": "2c97aef3-b747-49f7-99e0-4086c03e4200"
      },
      "source": [
        "## Installation and Import `rggrader` Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
      "metadata": {
        "id": "36c07e23-0280-467f-b0d2-44d966253bb4"
      },
      "outputs": [],
      "source": [
        "%pip install rggrader\n",
        "from rggrader import submit_image\n",
        "from rggrader import submit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3",
      "metadata": {
        "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3"
      },
      "source": [
        "# Working Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
      "metadata": {
        "id": "c1fb239a-1c81-4476-9009-d87abadf9506"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "from google.colab import files\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "tgn9oEU8VBZ3"
      },
      "id": "tgn9oEU8VBZ3",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "EERS7OVjVHYp"
      },
      "id": "EERS7OVjVHYp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d alessiocorrado99/animals10\n",
        "!unzip animals10.zip"
      ],
      "metadata": {
        "id": "BExrWS5cVJz7"
      },
      "id": "BExrWS5cVJz7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/raw-img'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(128, padding=10),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "num_classes = len(dataset.classes)\n",
        "print(\"Number of classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB-umAD9W1cd",
        "outputId": "eb94dbab-b39e-4399-e775-a144fa94cb3d"
      },
      "id": "TB-umAD9W1cd",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Animal(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Animal, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu4(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Animal(num_classes=10)"
      ],
      "metadata": {
        "id": "gdNFwcfUXMdH"
      },
      "id": "gdNFwcfUXMdH",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "u-P72bjmXs-U"
      },
      "id": "u-P72bjmXs-U",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sBUDzv3X00P",
        "outputId": "177c878d-39ef-43df-e400-70f52ae6f0dc"
      },
      "id": "1sBUDzv3X00P",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Loss: 2.355769860835476\n",
            "Epoch 2/50 - Loss: 1.9317672170755518\n",
            "Epoch 3/50 - Loss: 1.8346729839121112\n",
            "Epoch 4/50 - Loss: 1.7638332659961613\n",
            "Epoch 5/50 - Loss: 1.6772121760681384\n",
            "Epoch 6/50 - Loss: 1.6087647084971421\n",
            "Epoch 7/50 - Loss: 1.5636871415240163\n",
            "Epoch 8/50 - Loss: 1.5132019201307807\n",
            "Epoch 9/50 - Loss: 1.474518609410934\n",
            "Epoch 10/50 - Loss: 1.4167088011748918\n",
            "Epoch 11/50 - Loss: 1.380776459661149\n",
            "Epoch 12/50 - Loss: 1.3475199597482463\n",
            "Epoch 13/50 - Loss: 1.324586610029672\n",
            "Epoch 14/50 - Loss: 1.2906960429126069\n",
            "Epoch 15/50 - Loss: 1.2656289619343881\n",
            "Epoch 16/50 - Loss: 1.2393328466488205\n",
            "Epoch 17/50 - Loss: 1.2174797716941543\n",
            "Epoch 18/50 - Loss: 1.1897978723504161\n",
            "Epoch 19/50 - Loss: 1.18845326090587\n",
            "Epoch 20/50 - Loss: 1.1580153109463116\n",
            "Epoch 21/50 - Loss: 1.1428411984261666\n",
            "Epoch 22/50 - Loss: 1.1071994488475887\n",
            "Epoch 23/50 - Loss: 1.0865366315113678\n",
            "Epoch 24/50 - Loss: 1.0745721316519585\n",
            "Epoch 25/50 - Loss: 1.0504196204301965\n",
            "Epoch 26/50 - Loss: 1.0338013891045374\n",
            "Epoch 27/50 - Loss: 1.018231852181995\n",
            "Epoch 28/50 - Loss: 0.9996212880575019\n",
            "Epoch 29/50 - Loss: 0.9805163751576693\n",
            "Epoch 30/50 - Loss: 0.9811366348321201\n",
            "Epoch 31/50 - Loss: 0.9504033407182184\n",
            "Epoch 32/50 - Loss: 0.9377568345033486\n",
            "Epoch 33/50 - Loss: 0.932037624830508\n",
            "Epoch 34/50 - Loss: 0.9084375673122989\n",
            "Epoch 35/50 - Loss: 0.882308319734253\n",
            "Epoch 36/50 - Loss: 0.8596217460759723\n",
            "Epoch 37/50 - Loss: 0.8547131998393371\n",
            "Epoch 38/50 - Loss: 0.8357405162494601\n",
            "Epoch 39/50 - Loss: 0.8125383602753851\n",
            "Epoch 40/50 - Loss: 0.8022324433763519\n",
            "Epoch 41/50 - Loss: 0.7838423117426515\n",
            "Epoch 42/50 - Loss: 0.7729321050734921\n",
            "Epoch 43/50 - Loss: 0.7521109499094141\n",
            "Epoch 44/50 - Loss: 0.747000593493003\n",
            "Epoch 45/50 - Loss: 0.7303509711309244\n",
            "Epoch 46/50 - Loss: 0.7145362950008334\n",
            "Epoch 47/50 - Loss: 0.7029798667394478\n",
            "Epoch 48/50 - Loss: 0.6894842404445619\n",
            "Epoch 49/50 - Loss: 0.6743996803769629\n",
            "Epoch 50/50 - Loss: 0.6649769172413659\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy on test set: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr9fGuEEX-nu",
        "outputId": "72cddd94-e3e4-47f9-8e40-4f9272d37de4"
      },
      "id": "dr9fGuEEX-nu",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 74.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/model.pth')"
      ],
      "metadata": {
        "id": "8D4ydgiaYEcl"
      },
      "id": "8D4ydgiaYEcl",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "_SOeLzCL1dWa"
      },
      "id": "_SOeLzCL1dWa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = ['Dog', 'Horse', 'Elephant', 'Butterfly', 'Chicken', 'Cat', 'Cow', 'Sheep', 'Spider', 'Squirrel']\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "model = Animal()\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "model.to('cuda')\n",
        "model.eval()\n",
        "\n",
        "def predict_class_with_confidence(input_image):\n",
        "    input_image = Image.fromarray(input_image)\n",
        "    input_image = transform(input_image).unsqueeze(0).to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_image)\n",
        "\n",
        "    _, predicted_class = torch.max(output.data, 1)\n",
        "    predicted_label = class_labels[predicted_class.item()]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_class_with_confidence,\n",
        "    inputs=gr.inputs.Image(),\n",
        "    outputs=\"text\",\n",
        "    live=True,\n",
        "    capture_session=True,\n",
        "    title=\"Animal Classification App\",\n",
        "    description=\"Upload an image of an animal to classify it\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "tQ-1DeTvgz1t",
        "outputId": "2cd5ab0f-d130-4288-c13a-03762ee1d0a1"
      },
      "id": "tQ-1DeTvgz1t",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-8d1e24576838>:27: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Image(),\n",
            "<ipython-input-14-8d1e24576838>:27: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Image(),\n",
            "<ipython-input-14-8d1e24576838>:25: GradioDeprecationWarning: `capture_session` parameter is deprecated, and it has no effect\n",
            "  iface = gr.Interface(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ffb73d361c51ca0827.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ffb73d361c51ca0827.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b151c52-20a3-432f-ab16-4721c16581c4",
      "metadata": {
        "id": "2b151c52-20a3-432f-ab16-4721c16581c4"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
      "metadata": {
        "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e1d13494-2a01-4e38-9a16-0ad394389f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Assignment successfully submitted'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "portfolio_link = \"https://huggingface.co/spaces/Mangara01/Animal-Classification\"\n",
        "\n",
        "question_id = \"01_image_portfolio_link\"\n",
        "submit(student_id, name, assignment_id, str(portfolio_link), question_id, drive_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792aa177-c74e-42e5-9881-40376cd746a8",
      "metadata": {
        "id": "792aa177-c74e-42e5-9881-40376cd746a8"
      },
      "source": [
        "# FIN"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "be58b994-bc68-4166-91d5-282418b78864"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}